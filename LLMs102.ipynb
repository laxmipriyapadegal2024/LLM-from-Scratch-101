{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHvMg3tPnK5v27ASQ6pa2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmipriyapadegal2024/LLM-from-Scratch-101/blob/main/LLMs102.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Byte Pair Encoding**"
      ],
      "metadata": {
        "id": "hiiz0f__k4QJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcDoVz0JcJew",
        "outputId": "62c3e100-b75f-4e56-aa53-fb69e887f380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken,importlib\n",
        "print(\"tiktoken version: \",importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TqXqjdj7nQ",
        "outputId": "a5ff6b64-8bef-4f48-a4bd-c26c2a570187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version:  0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "vwCrwIh3k2tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=(\"Hey do you know about dark chocolate? <|endoftext|> I\"\n",
        "      \" study computerscience in University.\")\n",
        "ids=tokenizer.encode(test,allowed_special={\"<|endoftext|>\"})\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yns8uSblluoe",
        "outputId": "47c53d36-7a05-4419-a094-2bd3c10f2341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10814, 466, 345, 760, 546, 3223, 11311, 30, 220, 50256, 314, 2050, 9061, 4234, 287, 2059, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=tokenizer.decode(ids)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LtzbxqzndcO",
        "outputId": "279347df-847f-46fe-9d31-cd2f9cbec795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey do you know about dark chocolate? <|endoftext|> I study computerscience in University.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATING INPUT-TARGET PAIRS**"
      ],
      "metadata": {
        "id": "VZLv8pm46TIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "enc_text=tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "EbcBl4M1nrNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e84d80-0b8f-46e6-c667-7c351a8a5943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ttYLNYv5UX6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.output_ids=[]\n",
        "\n",
        "    token_ids=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk=token_ids[i:i+max_length]\n",
        "      output_chunk=token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.output_ids.append(torch.tensor(output_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.output_ids[idx]"
      ],
      "metadata": {
        "id": "KYm781dsLvLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,\n",
        "                         shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset=GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader=DataLoader(dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=shuffle,\n",
        "                        drop_last=drop_last,\n",
        "                        num_workers=num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "S1QL-xE8ZEqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\",torch.__version__)\n",
        "dataloader=create_dataloader_v1(raw_text,batch_size=128,max_length=4,\n",
        "                                stride=4,shuffle=False)\n",
        "\n",
        "data_iter=iter(dataloader)\n",
        "first_batch=next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2EZRyAV4J1H",
        "outputId": "b090ee80-bbe5-4f3a-d211-f4e394f836bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "[tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11],\n",
            "        [  287,   262,  6001,   286],\n",
            "        [  465, 13476,    11,   339],\n",
            "        [  550,  5710,   465, 12036],\n",
            "        [   11,  6405,   257,  5527],\n",
            "        [27075,    11,   290,  4920],\n",
            "        [ 2241,   287,   257,  4489],\n",
            "        [   64,   319,   262, 34686],\n",
            "        [41976,    13,   357, 10915],\n",
            "        [  314,  2138,  1807,   340],\n",
            "        [  561,   423,   587, 10598],\n",
            "        [  393, 28537,  2014,   198],\n",
            "        [  198,     1,   464,  6001],\n",
            "        [  286,   465, 13476,     1],\n",
            "        [  438,  5562,   373,   644],\n",
            "        [  262,  1466,  1444,   340],\n",
            "        [   13,   314,   460,  3285],\n",
            "        [ 9074,    13, 46606,   536],\n",
            "        [ 5469,   438, 14363,   938],\n",
            "        [ 4842,  1650,   353,   438],\n",
            "        [ 2934,   489,  3255,   465],\n",
            "        [48422,   540,   450,    67],\n",
            "        [ 3299,    13,   366,  5189],\n",
            "        [ 1781,   340,   338,  1016],\n",
            "        [  284,  3758,   262,  1988],\n",
            "        [  286,   616,  4286,   705],\n",
            "        [ 1014,   510,    26,   475],\n",
            "        [  314,   836,   470,   892],\n",
            "        [  286,   326,    11,  1770],\n",
            "        [   13,  8759,  2763,   438],\n",
            "        [ 1169,  2994,   284,   943],\n",
            "        [17034,   318,   477,   314],\n",
            "        [  892,   286,   526,   383],\n",
            "        [ 1573,    11,   319,  9074],\n",
            "        [   13,   536,  5469,   338],\n",
            "        [11914,    11, 33096,   663],\n",
            "        [ 4808,  3808,    62,   355],\n",
            "        [  996,   484,   547, 12548],\n",
            "        [  287,   281, 13079,   410],\n",
            "        [12523,   286, 22353,    13],\n",
            "        [  843,   340,   373,   407],\n",
            "        [  691,   262,  9074,    13],\n",
            "        [  536, 48819,   508, 25722],\n",
            "        [  276,    13, 11161,   407],\n",
            "        [  262, 40123, 18113,   544],\n",
            "        [ 9325,   701,    11,   379],\n",
            "        [  262,   938,   402,  1617],\n",
            "        [  261, 12917,   905,    11],\n",
            "        [ 5025,   502,   878,   402],\n",
            "        [  271, 10899,   338,   366],\n",
            "        [31640,    12,    67, 20811],\n",
            "        [    1,   284,   910,    11],\n",
            "        [  351, 10953,   287,   607],\n",
            "        [ 2951,    25,   366,  1135],\n",
            "        [ 2236,   407,   804,  2402],\n",
            "        [  663,   588,   757, 13984],\n",
            "        [  198,   198,  5779, 28112],\n",
            "        [10197,   832,   262, 46475],\n",
            "        [  286, 18113,   544,   338],\n",
            "        [10953,   314,  2936,  1498],\n",
            "        [  284,  1986,   262,  1109],\n",
            "        [  351,  1602, 11227,   414],\n",
            "        [   13, 23676,  3619,   402],\n",
            "        [  271, 10899,     0,   383],\n",
            "        [ 1466,   550,   925,   683],\n",
            "        [  438,   270,   373, 15830],\n",
            "        [  326,   484,   815, 25722],\n",
            "        [  683,    13,  9754,   465],\n",
            "        [  898,  1714,  7380, 30090],\n",
            "        [  547,  2982,    11,   290],\n",
            "        [  287,   465,   898,  3292],\n",
            "        [ 8941,   257,  4636, 28582],\n",
            "        [   13, 18612, 35394,    30],\n",
            "        [ 8673,    13,  1002,   340],\n",
            "        [  547,    11,   262, 15393],\n",
            "        [  286,   262,  5977,   373],\n",
            "        [29178,  3474,   416,  1310],\n",
            "        [40559, 11959,  1636,    11],\n",
            "        [  508,    11,   287,   477],\n",
            "        [  922,  4562,    11,  3181],\n",
            "        [  503,   287,   262, 37090],\n",
            "        [  257,   845, 22665,   366],\n",
            "        [  672,   270,  2838,     1],\n",
            "        [  319,  3619,   438,   505],\n",
            "        [  286,   883,   905,    88],\n",
            "        [ 6685, 42070,   351,  4738],\n",
            "        [ 6276,   871,   326,   314],\n",
            "        [  423,  2982,   357,    40],\n",
            "        [ 1839,   470,   910,   416],\n",
            "        [ 4150,     8,  3688,   284],\n",
            "        [  402,   271, 10899,   338],\n",
            "        [12036,    13,   843,   523],\n",
            "        [  438, 14363, 10568,   852],\n",
            "        [ 5729, 11331, 18893,   540],\n",
            "        [  438,  1169,  5114, 11835],\n",
            "        [ 3724,   503,    11,   290],\n",
            "        [   11,   355,  9074,    13],\n",
            "        [  536,  5469,   550, 11001],\n",
            "        [   11,   262,  2756,   286],\n",
            "        [  366,    38,   271, 10899],\n",
            "        [   82,     1,  1816,   510],\n",
            "        [   13,   198,   198,  1026],\n",
            "        [  373,   407, 10597,  1115],\n",
            "        [  812,  1568,   326,    11],\n",
            "        [  287,   262,  1781,   286],\n",
            "        [  257,  1178,  2745,     6],\n",
            "        [ 4686,  1359,   319,   262],\n",
            "        [34686, 41976,    11,   340],\n",
            "        [ 6451,  5091,   284,   502],\n",
            "        [  284,  4240,  1521,   402],\n",
            "        [  271, 10899,   550,  1813],\n",
            "        [  510,   465, 12036,    13],\n",
            "        [ 1550, 14580,    11,   340],\n",
            "        [ 1107,   373,   257, 29850],\n",
            "        [ 1917,    13,  1675, 24456],\n",
            "        [  465,  3656,   561,   423],\n",
            "        [  587,  1165,  2562,   438],\n",
            "        [14363,  3148,  1650,  1010],\n",
            "        [  550,   587,  6699,   262],\n",
            "        [ 1540,   558,   286,  2282],\n",
            "        [  326,  9074,    13,   402]]), tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287],\n",
            "        [  262,  6001,   286,   465],\n",
            "        [13476,    11,   339,   550],\n",
            "        [ 5710,   465, 12036,    11],\n",
            "        [ 6405,   257,  5527, 27075],\n",
            "        [   11,   290,  4920,  2241],\n",
            "        [  287,   257,  4489,    64],\n",
            "        [  319,   262, 34686, 41976],\n",
            "        [   13,   357, 10915,   314],\n",
            "        [ 2138,  1807,   340,   561],\n",
            "        [  423,   587, 10598,   393],\n",
            "        [28537,  2014,   198,   198],\n",
            "        [    1,   464,  6001,   286],\n",
            "        [  465, 13476,     1,   438],\n",
            "        [ 5562,   373,   644,   262],\n",
            "        [ 1466,  1444,   340,    13],\n",
            "        [  314,   460,  3285,  9074],\n",
            "        [   13, 46606,   536,  5469],\n",
            "        [  438, 14363,   938,  4842],\n",
            "        [ 1650,   353,   438,  2934],\n",
            "        [  489,  3255,   465, 48422],\n",
            "        [  540,   450,    67,  3299],\n",
            "        [   13,   366,  5189,  1781],\n",
            "        [  340,   338,  1016,   284],\n",
            "        [ 3758,   262,  1988,   286],\n",
            "        [  616,  4286,   705,  1014],\n",
            "        [  510,    26,   475,   314],\n",
            "        [  836,   470,   892,   286],\n",
            "        [  326,    11,  1770,    13],\n",
            "        [ 8759,  2763,   438,  1169],\n",
            "        [ 2994,   284,   943, 17034],\n",
            "        [  318,   477,   314,   892],\n",
            "        [  286,   526,   383,  1573],\n",
            "        [   11,   319,  9074,    13],\n",
            "        [  536,  5469,   338, 11914],\n",
            "        [   11, 33096,   663,  4808],\n",
            "        [ 3808,    62,   355,   996],\n",
            "        [  484,   547, 12548,   287],\n",
            "        [  281, 13079,   410, 12523],\n",
            "        [  286, 22353,    13,   843],\n",
            "        [  340,   373,   407,   691],\n",
            "        [  262,  9074,    13,   536],\n",
            "        [48819,   508, 25722,   276],\n",
            "        [   13, 11161,   407,   262],\n",
            "        [40123, 18113,   544,  9325],\n",
            "        [  701,    11,   379,   262],\n",
            "        [  938,   402,  1617,   261],\n",
            "        [12917,   905,    11,  5025],\n",
            "        [  502,   878,   402,   271],\n",
            "        [10899,   338,   366, 31640],\n",
            "        [   12,    67, 20811,     1],\n",
            "        [  284,   910,    11,   351],\n",
            "        [10953,   287,   607,  2951],\n",
            "        [   25,   366,  1135,  2236],\n",
            "        [  407,   804,  2402,   663],\n",
            "        [  588,   757, 13984,   198],\n",
            "        [  198,  5779, 28112, 10197],\n",
            "        [  832,   262, 46475,   286],\n",
            "        [18113,   544,   338, 10953],\n",
            "        [  314,  2936,  1498,   284],\n",
            "        [ 1986,   262,  1109,   351],\n",
            "        [ 1602, 11227,   414,    13],\n",
            "        [23676,  3619,   402,   271],\n",
            "        [10899,     0,   383,  1466],\n",
            "        [  550,   925,   683,   438],\n",
            "        [  270,   373, 15830,   326],\n",
            "        [  484,   815, 25722,   683],\n",
            "        [   13,  9754,   465,   898],\n",
            "        [ 1714,  7380, 30090,   547],\n",
            "        [ 2982,    11,   290,   287],\n",
            "        [  465,   898,  3292,  8941],\n",
            "        [  257,  4636, 28582,    13],\n",
            "        [18612, 35394,    30,  8673],\n",
            "        [   13,  1002,   340,   547],\n",
            "        [   11,   262, 15393,   286],\n",
            "        [  262,  5977,   373, 29178],\n",
            "        [ 3474,   416,  1310, 40559],\n",
            "        [11959,  1636,    11,   508],\n",
            "        [   11,   287,   477,   922],\n",
            "        [ 4562,    11,  3181,   503],\n",
            "        [  287,   262, 37090,   257],\n",
            "        [  845, 22665,   366,   672],\n",
            "        [  270,  2838,     1,   319],\n",
            "        [ 3619,   438,   505,   286],\n",
            "        [  883,   905,    88,  6685],\n",
            "        [42070,   351,  4738,  6276],\n",
            "        [  871,   326,   314,   423],\n",
            "        [ 2982,   357,    40,  1839],\n",
            "        [  470,   910,   416,  4150],\n",
            "        [    8,  3688,   284,   402],\n",
            "        [  271, 10899,   338, 12036],\n",
            "        [   13,   843,   523,   438],\n",
            "        [14363, 10568,   852,  5729],\n",
            "        [11331, 18893,   540,   438],\n",
            "        [ 1169,  5114, 11835,  3724],\n",
            "        [  503,    11,   290,    11],\n",
            "        [  355,  9074,    13,   536],\n",
            "        [ 5469,   550, 11001,    11],\n",
            "        [  262,  2756,   286,   366],\n",
            "        [   38,   271, 10899,    82],\n",
            "        [    1,  1816,   510,    13],\n",
            "        [  198,   198,  1026,   373],\n",
            "        [  407, 10597,  1115,   812],\n",
            "        [ 1568,   326,    11,   287],\n",
            "        [  262,  1781,   286,   257],\n",
            "        [ 1178,  2745,     6,  4686],\n",
            "        [ 1359,   319,   262, 34686],\n",
            "        [41976,    11,   340,  6451],\n",
            "        [ 5091,   284,   502,   284],\n",
            "        [ 4240,  1521,   402,   271],\n",
            "        [10899,   550,  1813,   510],\n",
            "        [  465, 12036,    13,  1550],\n",
            "        [14580,    11,   340,  1107],\n",
            "        [  373,   257, 29850,  1917],\n",
            "        [   13,  1675, 24456,   465],\n",
            "        [ 3656,   561,   423,   587],\n",
            "        [ 1165,  2562,   438, 14363],\n",
            "        [ 3148,  1650,  1010,   550],\n",
            "        [  587,  6699,   262,  1540],\n",
            "        [  558,   286,  2282,   326],\n",
            "        [ 9074,    13,   402,   271]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector/Token Embeddings**"
      ],
      "metadata": {
        "id": "87xCbje0o3uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simulation**"
      ],
      "metadata": {
        "id": "0wJIT_YmehTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip uninstall numpy -y\n",
        "!pip install numpy\n",
        "!pip uninstall gensim -y\n",
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "ilv1TWVhsRtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fe7f84-1a0f-4ff0-8add-440184045242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use"
      ],
      "metadata": {
        "id": "xj5VnyvSk9jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors=model\n",
        "print(word_vectors['computer']) #vector dimension is 300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywbPe7_18y_l",
        "outputId": "e3aaf7e8-f99b-4156-b388-c11afcfe9547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
            " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
            "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
            "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
            " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
            " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
            "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
            "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
            " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
            " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
            " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
            "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
            " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
            "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
            "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
            "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
            " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
            " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
            "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
            "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
            "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
            "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
            " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
            " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
            "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
            "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
            " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
            "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
            " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
            " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
            " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
            " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
            "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
            " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
            "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
            "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
            " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
            " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
            " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
            " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
            " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
            " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
            " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
            " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
            "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
            " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
            "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
            "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
            " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
            "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
            " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
            "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
            " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
            " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
            " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
            " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
            " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
            " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
            " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
            "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
            "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
            " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
            "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
            " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
            "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
            " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
            "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
            " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
            " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
            " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
            "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
            "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
            "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
            "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
            "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfO1YTYLW2Y",
        "outputId": "366009c3-fe77-4b47-a4ae-29e72657360c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593831062317), ('monarchy', 0.5087411999702454)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's make Token Embeddings**"
      ],
      "metadata": {
        "id": "6jfbPWgUMhL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "MPxElNlQLmYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRamzUMMQGmc",
        "outputId": "27807682-6939-42ef-8a4c-9c07983115bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5K5Mk1sQKR1",
        "outputId": "1686e631-f5fe-4c77-de80-7e35490ea77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-NFlSaSQReO",
        "outputId": "0701c344-ec7b-4130-c15d-47093ce64756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    }
  ]
}