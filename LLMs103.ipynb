{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvBhtxshKadEZDq5GdvjWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmipriyapadegal2024/LLM-from-Scratch-101/blob/main/LLMs103.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch,tiktoken\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")   # byte-pair encoding"
      ],
      "metadata": {
        "id": "7dngIBwKcBxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "enc_text=tokenizer.encode(raw_text)           #converting our text to tokens\n",
        "print(len(enc_text))\n",
        "print(enc_text[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HblpDerStw9_",
        "outputId": "0cb09c7a-060c-4175-88b5-f0c537233c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n",
            "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.output_ids=[]\n",
        "\n",
        "    token_ids=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk=token_ids[i:i+max_length]\n",
        "      output_chunk=token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.output_ids.append(torch.tensor(output_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.output_ids[idx]"
      ],
      "metadata": {
        "id": "N_3flMTsti9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,\n",
        "                         shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset=GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader=DataLoader(dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=shuffle,\n",
        "                        drop_last=drop_last,\n",
        "                        num_workers=num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "xy1O-9Dqtj1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGWUtDDoYzMS"
      },
      "outputs": [],
      "source": [
        "vocab_size=50257\n",
        "output_dim=256\n",
        "token_embedding_layer=torch.nn.Embedding(vocab_size,input_dim) # Vector embedding initiations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=4\n",
        "stride=4\n",
        "batch_size=8\n",
        "dataloader=create_dataloader_v1(raw_text,batch_size=batch_size,\n",
        "            max_length=max_length,stride=stride,shuffle=False) #input-target pairs\n",
        "data_iter=iter(dataloader)\n",
        "inputs,targets=next(data_iter)\n",
        "print(\"Token IDs:\\n\",inputs)\n",
        "print(inputs.shape)"
      ],
      "metadata": {
        "id": "-8NhV16Xcf0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe26c6dc-5916-41ab-aac8-db874bbdd5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings=token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvqT7un0vzsr",
        "outputId": "90279731-c66e-45f6-e0fa-2fcac2e2eabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length=max_length\n",
        "pos_embedding_layer=torch.nn.Embedding(context_length,output_dim)"
      ],
      "metadata": {
        "id": "Rvsc24spyhbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using absolute positional embeddings\n",
        "pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlnIRnjey3XR",
        "outputId": "de636cef-0a44-4ef6-f9a7-5b0b14b7b846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings=token_embeddings+pos_embeddings\n",
        "print(input_embeddings.shape)\n",
        "print(input_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIFJG69zzEn",
        "outputId": "c0fae342-386c-4d4c-bd17-5f2477c9f998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n",
            "tensor([[[-1.0780, -2.4384, -1.1104,  ..., -0.0834, -0.7061, -0.8745],\n",
            "         [-0.4684, -2.1987,  1.5940,  ...,  0.3222, -0.5426,  1.0070],\n",
            "         [ 0.7537, -2.5357, -0.1171,  ..., -1.3008, -0.7795,  2.1786],\n",
            "         [-0.4568,  1.7411,  0.3138,  ...,  1.1688, -0.7644,  0.3278]],\n",
            "\n",
            "        [[ 0.0446, -2.3144, -0.5571,  ...,  2.9467, -0.8466, -1.7283],\n",
            "         [-1.7615, -1.1404,  0.0710,  ..., -0.2187, -1.9814, -1.3629],\n",
            "         [-1.2528, -3.8005, -0.2129,  ...,  0.0844,  0.2455,  1.5653],\n",
            "         [ 1.3436,  0.0562,  0.1808,  ...,  0.1614, -1.7230, -1.5271]],\n",
            "\n",
            "        [[ 1.5583, -1.4031, -2.2170,  ..., -0.4483,  1.0269, -0.2731],\n",
            "         [-0.6121, -0.2826,  0.4304,  ..., -1.0857, -0.5784,  1.2861],\n",
            "         [-2.3612, -3.5975, -2.1962,  ...,  0.5516,  1.3488,  2.3731],\n",
            "         [ 0.5100,  0.6005, -0.2229,  ..., -0.4433, -0.8191, -1.0586]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.9519, -3.7512, -0.8602,  ...,  0.6066, -0.6035, -1.5930],\n",
            "         [-2.8009, -1.1106, -1.8568,  ..., -0.9988, -0.3673,  0.3551],\n",
            "         [-1.1898, -1.9214, -0.0419,  ..., -0.8278,  0.9078,  2.2478],\n",
            "         [ 0.0881,  0.1417, -0.4313,  ...,  1.0740, -0.7494, -0.9804]],\n",
            "\n",
            "        [[ 0.2761, -0.5535, -0.4871,  ...,  1.0900, -1.2676,  1.3526],\n",
            "         [-1.5275, -2.1405,  0.2677,  ..., -1.3101, -0.9530, -1.1058],\n",
            "         [ 0.3630, -3.1491, -0.2860,  ..., -0.1219, -1.2254,  0.9339],\n",
            "         [ 0.8022, -0.5235,  0.1519,  ..., -1.3047,  0.4325,  0.2255]],\n",
            "\n",
            "        [[ 0.7948, -2.5451, -0.5542,  ...,  1.0411, -2.3092, -0.9046],\n",
            "         [-2.4486, -0.5822,  0.9484,  ..., -0.9177, -3.2001,  1.8092],\n",
            "         [-0.2834, -1.5861, -2.2445,  ..., -1.5441,  0.3682,  1.0191],\n",
            "         [ 0.6240, -0.0602, -3.0721,  ..., -0.0903, -1.2921, -0.8405]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}